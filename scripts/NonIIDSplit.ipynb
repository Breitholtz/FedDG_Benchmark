{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f08b3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import code_gpt_py\n",
    "from src.dataset_bundle import Py150\n",
    "import torch\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_train_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "import sys\n",
    "from re import L\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from wilds.datasets.wilds_dataset import WILDSSubset, WILDSDataset\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d702bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/local/scratch/a/shared/datasets/\"\n",
    "dataset = get_dataset(dataset='iwildcam', root_dir=root_dir, download=True)\n",
    "train_set = dataset.get_subset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cc050e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonIIDSplitter():\n",
    "    def __init__(self, num_shards, iid, seed):\n",
    "        \"\"\"\n",
    "        num_shards: split dataset to clients\n",
    "        iid: float from 0-1, describe how iid it is. iid=0 means each shard only contains images from one domain, iid=1 means each shard shares the same domain distribution.\n",
    "        \"\"\"\n",
    "        self.num_shards = num_shards\n",
    "        self.iid = iid\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.default_rng(self.seed)\n",
    "\n",
    "    def split(self, dataset, domain_field, transform=None):\n",
    "        '''\n",
    "        dataset: WILDSSubset\n",
    "        '''            \n",
    "        domain_field = dataset._metadata_fields.index(domain_field[0])\n",
    "        num_examples_per_domain = np.bincount(dataset.metadata_array[:,domain_field]) # compute number of examples per domain.\n",
    "        num_domains = len(num_examples_per_domain)                                # number of domains. Notice that we use bincount, that means the metaarray should be integer at least.\n",
    "        non_empty_num_domains = sum(num_examples_per_domain > 0)\n",
    "        if non_empty_num_domains <= self.num_shards:\n",
    "            main_shards_per_domain = (num_examples_per_domain > 0).astype('int')          # initialize the data structure to store each domainâ€˜s main shards \n",
    "            print(np.sum(main_shards_per_domain))\n",
    "            while np.sum(main_shards_per_domain) < self.num_shards:                       # start to distribute domain to \n",
    "                ratio = np.divide(num_examples_per_domain.astype('float'), main_shards_per_domain.astype('float'), out=np.zeros_like(num_examples_per_domain.astype('float')), where=main_shards_per_domain!=0)\n",
    "                argmax = np.argmax(ratio)\n",
    "                main_shards_per_domain[argmax] += 1\n",
    "            # print(main_shards_per_domain)\n",
    "            main_domain_per_shards = []\n",
    "            for i, num_shard in enumerate(main_shards_per_domain):\n",
    "                main_domain_per_shards += [i] * int(num_shard)\n",
    "            # print(main_domain_per_shards)\n",
    "            # print(len(main_domain_per_shards))\n",
    "            num_examples_per_shards = []\n",
    "            main_domain_ratio_per_shard = np.array([1/u if u != 0 else 0 for u in main_shards_per_domain]) # len = num_domains\n",
    "            non_main_domain_ratio_per_shard = 1/self.num_shards # len = num_domains\n",
    "            for i, main_domain in enumerate(main_domain_per_shards):\n",
    "                main_domain_onehot = np.zeros(len(main_shards_per_domain))\n",
    "                main_domain_onehot[main_domain] = 1\n",
    "                num_examples_per_shards.append(num_examples_per_domain * (main_domain_ratio_per_shard * main_domain_onehot * (1 - self.iid)\n",
    "                                        + non_main_domain_ratio_per_shard * self.iid))\n",
    "            np_examples_per_shards = np.array(num_examples_per_shards)\n",
    "            np_int_examples_per_shards = np_examples_per_shards.astype(int)\n",
    "            diff = np.rint(np.sum(np_examples_per_shards - np_int_examples_per_shards, axis=0)).astype(int)\n",
    "            diff_mask = np.zeros((self.num_shards,num_domains))\n",
    "            for col in range(num_domains):\n",
    "                diff_mask[0:diff[col],col] = 1\n",
    "                final_examples_per_shards = (np.rint(np_int_examples_per_shards + diff_mask)).astype(int)\n",
    "            \n",
    "        else:\n",
    "            num_examples_per_shards_0 = np.zeros((self.num_shards, num_domains))\n",
    "            desc_idx = np.argsort(num_examples_per_domain)[::-1]\n",
    "\n",
    "            for idx in desc_idx:\n",
    "                amin = np.argmin(np.sum(num_examples_per_shards_0, axis=1))\n",
    "                num_examples_per_shards_0[amin, idx] = num_examples_per_domain[idx]\n",
    "            \n",
    "            num_examples_per_shards_1 = np.zeros((self.num_shards, num_domains))\n",
    "            for shard in num_examples_per_shards_1:\n",
    "                shard += num_examples_per_domain / self.num_shards\n",
    "            float_final_examples_per_shards = num_examples_per_shards_1 * self.iid + num_examples_per_shards_0 * (1-self.iid)\n",
    "            # could be float need to change to int.\n",
    "            final_examples_per_shards = np.floor(float_final_examples_per_shards).astype('int')\n",
    "            diff_array = (num_examples_per_domain - np.sum(final_examples_per_shards, axis=0)).astype('int')\n",
    "            for i, diff in enumerate(diff_array):\n",
    "                for d in range(diff):\n",
    "                    final_examples_per_shards[d, i] += 1\n",
    "\n",
    "            assert np.sum(num_examples_per_domain - np.sum(final_examples_per_shards, axis=0)) == 0\n",
    "        indices_per_domain = [] # assert len(indices_per_domain) == num_domains\n",
    "        for i in range(num_domains):\n",
    "            sub_indices = np.where(dataset.metadata_array[:,domain_field] == i)[0]\n",
    "            if isinstance(dataset, WILDSSubset):\n",
    "                indices = np.array(dataset.indices)[sub_indices]\n",
    "            elif isinstance(dataset, WILDSDataset):\n",
    "                indices = sub_indices\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "            perm_indices = self.rng.permutation(indices)\n",
    "            indices_per_domain.append(perm_indices)\n",
    "\n",
    "        dataset_per_shards = []\n",
    "        pointer = np.zeros(num_domains, dtype=np.int64)\n",
    "        # print(pointer) \n",
    "        for shard in range(self.num_shards):\n",
    "            shard_indices = []\n",
    "        # use subset and concatdataset to do so.\n",
    "            for j, _ in enumerate(final_examples_per_shards[shard]):\n",
    "                # assert len(final_examples_per_domain) == num_domains\n",
    "                offset = final_examples_per_shards[shard,j]\n",
    "                if offset > 0:\n",
    "                    shard_indices += (indices_per_domain[j][pointer[j]:pointer[j]+offset]).tolist()\n",
    "                    pointer[j] += offset\n",
    "            if isinstance(dataset, WILDSSubset):\n",
    "                dataset_per_shards.append(WILDSSubset(dataset.dataset, shard_indices, transform=transform))\n",
    "            elif isinstance(dataset, WILDSDataset):\n",
    "                dataset_per_shards.append(WILDSSubset(dataset, shard_indices, transform=transform))\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "        assert np.array_equal(pointer, num_examples_per_domain)\n",
    "\n",
    "        for i, dt in enumerate(dataset_per_shards):\n",
    "            assert np.array_equal(np.array(np.bincount(dt.metadata_array[:,domain_field], minlength=num_domains)), np.array(final_examples_per_shards[i]))\n",
    "        return dataset_per_shards\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3e4c3856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "datasets = NonIIDSplitter(num_shards=132, iid=0.2, seed=8989).split(train_set, [\"location\",])\n",
    "bincount = np.bincount(train_set.metadata_array[:,0])\n",
    "for dataset in datasets:\n",
    "    bincount -= np.bincount(dataset.metadata_array[:,0], minlength=len(bincount))\n",
    "print(bincount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f11ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2609072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
